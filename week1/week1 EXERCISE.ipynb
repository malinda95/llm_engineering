{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# constants\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c25f6cbd-ef91-4b16-aae5-60d36d1065cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that takes a technical question and respond with an explanation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42d4fbe3-767c-4d56-9874-8110a1ebecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_prompt(question):\n",
    "    user_prompt = \"You are going to answer this technical question.\\n\"\n",
    "    user_prompt += question\n",
    "    user_prompt += \"\\nProvide the solution with an explanation in markdown.\"\n",
    "    return user_prompt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "def answer_technical_question(question):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL_GPT,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": create_user_prompt(question)},\n",
    "        ],\n",
    "        stream = True\n",
    "    )\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        # response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Let's break down the code snippet `yield from {book.get(\"author\") for book in books if book.get(\"author\")}`.\n",
       "\n",
       "### Explanation\n",
       "\n",
       "1. **Context of `yield from`**: \n",
       "   - The `yield from` expression in Python is used within a generator function to yield all values from an iterable. This effectively delegates the generator's operations to another generator or iterable, enabling a clean and efficient way to yield multiple values.\n",
       "\n",
       "2. **The Set Comprehension**:\n",
       "   - `{book.get(\"author\") for book in books if book.get(\"author\")}` is a **set comprehension**. Set comprehensions are used to create a new set by iterating over an iterable (in this case, `books`), applying an expression, and optionally filtering the items based on a condition.\n",
       "   - Here, for each `book` in the `books` iterable, `book.get(\"author\")` is called. This attempts to retrieve the value associated with the key `\"author\"` from each `book`.\n",
       "   - The condition `if book.get(\"author\")` filters the books to include only those that have a truthy value for the `\"author\"` key. In Python, this means it will exclude any books where the `\"author\"` is either `None`, an empty string, or any other falsey value.\n",
       "\n",
       "3. **Conversion to a Set**:\n",
       "   - The result of the set comprehension is a set of unique authors. A set automatically handles duplicates, so if multiple books have the same author, that author will only appear once in the final result.\n",
       "\n",
       "4. **Putting It All Together**:\n",
       "   - The entire code line effectively gathers all the unique authors from a collection of books and yields them one by one. \n",
       "   - Since the expression is wrapped with `yield from`, if this line is inside a generator function, it allows the function to yield each unique author directly to the caller, streamlining the process compared to yielding each author individually.\n",
       "\n",
       "### Example\n",
       "\n",
       "Here is a simple example for clarity:\n",
       "\n",
       "```python\n",
       "books = [\n",
       "    {\"title\": \"Book 1\", \"author\": \"Author A\"},\n",
       "    {\"title\": \"Book 2\", \"author\": \"Author A\"},\n",
       "    {\"title\": \"Book 3\", \"author\": \"Author B\"},\n",
       "    {\"title\": \"Book 4\", \"author\": None},\n",
       "    {\"title\": \"Book 5\", \"author\": \"Author C\"},\n",
       "]\n",
       "\n",
       "def get_unique_authors(books):\n",
       "    yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "# Usage\n",
       "for author in get_unique_authors(books):\n",
       "    print(author)\n",
       "```\n",
       "\n",
       "### Output\n",
       "\n",
       "In this case, the output would be:\n",
       "```\n",
       "Author A\n",
       "Author B\n",
       "Author C\n",
       "```\n",
       "\n",
       "### Summary\n",
       "\n",
       "In summary, the code efficiently extracts unique author names from a list of books while ignoring books without an author. It combines the power of set comprehensions and generator functions in Python to produce a streamlined and efficient solution for obtaining and yielding unique authors."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "answer_technical_question(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "\n",
    "def answer_technical_question_ollama(question):\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": create_user_prompt(question)},\n",
    "        ]\n",
    "    payload = {\n",
    "        \"model\": MODEL_LLAMA,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    } \n",
    "    response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "    display(Markdown(response.json()['message']['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba938758-2643-4e54-b901-5a53f515c152",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Decoupling Looping Over Collections**\n",
       "======================================\n",
       "\n",
       "The given code utilizes a feature of Python called **generators and `yield`** to break down a complex loop into smaller, more manageable pieces.\n",
       "\n",
       "### Code Explanation\n",
       "```python\n",
       "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "```\n",
       "This line is written in a combination of Python syntax. Here's what it does:\n",
       "\n",
       "*   `{...}`: This is a set comprehension, which creates an iterator that yields elements from the `books` collection.\n",
       "*   `for book in books`: This part iterates over each item (book) in the `books` collection.\n",
       "*   `if book.get(\"author\")`: Before yielding the author of a book, this condition filters out any book that does not have an \"author\" key or value.\n",
       "*   `yield from {...}`: Instead of explicitly iterating and yielding elements with `.next()`, we use `yield from`. This tells Python to yield all values generated by the inner iterable.\n",
       "\n",
       "### How It Works\n",
       "\n",
       "Here's a step-by-step breakdown:\n",
       "\n",
       "1.  Iterate over each book in the `books` collection.\n",
       "2.  Filter out any books that do not have an \"author\" key or value.\n",
       "3.  For each book with an author, yield their name.\n",
       "\n",
       "**Example Use Case**\n",
       "\n",
       "Suppose we have two dictionaries representing books:\n",
       "```python\n",
       "books = [\n",
       "    {\"title\": \"Book A\", \"author\": \"John Doe\"},\n",
       "    {\"title\": \"Book B\", \"author\": None},\n",
       "    {\"title\": \"Book C\", \"author\": \"Jane Smith\"}\n",
       "]\n",
       "```\n",
       "Running the given code will produce an iterator with the following values:\n",
       "\n",
       "```python\n",
       "[\"John Doe\", \"Jane Smith\"]\n",
       "```\n",
       "\n",
       "This is because only books with an author have been included in the output."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer_technical_question_ollama(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22891dc9-b613-495c-9e2e-2885efcdca2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
